trnslist[1] %>% as_tibble()
trnslist %>% as_tibble()
[1]
library(rstudioapi)
library(tidyverse)
library(dplyr)
library(rvest)
library(rlist)
library(tidytext)
source('transcriptTED.R')
setwd(dirname(getSourceEditorContext()$path))
# Disable text encoding as 'factors'
options(stringsAsFactors = FALSE)
# URL of the playlist
# "https://www.ted.com/playlists/78/climate_change_oh_it_s_real"
# "https://www.ted.com/playlists/126/the_big_picture"
playlisturl <- "https://www.ted.com/playlists/78/climate_change_oh_it_s_real"
htmlpage <- playlisturl %>% read_html()
htmlpage %>% write_html("playlist.html")
# scrape list of videos from playlist
videolist <- htmlpage %>% html_nodes('body') %>%
html_nodes('a') %>%
html_attr('href') %>%
as.vector() %>%
gsub(pattern = '\\?(.*)', replacement = "")
# clean list of video
videolist <- videolist[grep(x = videolist, pattern = '/talks/')]
videolist <- videolist[-1]
videolist <- paste('https://www.ted.com/', videolist, '/transcript', sep = "")
trnslist <- vector()
for (val in videolist) {
temp <- val %>% transcriptTED()
trnslist <- trnslist %>% list.append(temp)
}
strn <- "TED.com translations are made possible by volunteer translators. Learn more about the Open Translation Project."
trnslist <- trnslist[-grep(pattern = strn, x = trnslist)]
strn <- "© TED Conferences, LLC. All rights reserved."
trnslist <- trnslist %>% gsub(pattern = strn,replacement = "©")
trnslist <- split(trnslist, cumsum(trnslist == "©"))
trnslist <- trnslist[-length(trnslist)]
trnslist %>% saveRDS(file = "texttranscription.rds")
for (val in 1:length(trnslist)) {
trnslist[val] %>% as_tibble()
}
for (val in 1:length(trnslist)) {
trnslist[val] <- trnslist[val] %>% as_tibble()
}
View(trnslist)
trnslist[["0"]]
trnslist
for (val in length(trnslist)) {
print(val)
trnslist[val] <- trnslist[val] %>% as_tibble()
}
for (val in 1:length(trnslist)) {
print(val)
trnslist[val] <- trnslist[val] %>% as_tibble()
}
for (val in 1:length(trnslist)) {
print(val)
trnslist[val] <- trnslist[val] %>% as_tibble()
}
View(trnslist)
t <- list()
for (val in 1:length(trnslist)) {
print(val)
t[val] <- trnslist[val] %>% as_tibble()
}
View(t)
t[[1]]
View(trnslist)
source('C:/Users/fcalv/Desktop/R folder/Climatedream/TED/script.R', echo=TRUE)
trnslist %>% lengths()
trnslist[1] %>% lengths()
df <- tibble(line = 1:tail(lengths(trnslist[1]),1), text = trnslist[1])
glimpse(df)
view(df)
df <- tibble(line = 1:tail(lengths(trnslist[1]),1), text = trnslist)
df <- tibble(line = 1:tail(lengths(trnslist[1]),1), text = trnslist[0])
df <- tibble(line = 1:tail(lengths(trnslist[1]),1), text = trnslist[1])
view(df)
trnslist %>% glimpse()
trnslist[1]
df <- tibble(line = 1:tail(lengths(trnslist[1]),1), text = as.vector(trnslist[1]))
df
view(df)
df <- trnslist[1] %>% as.data.frame()
df
glimpse(df)
View(df)
df %>%
unnest_tokens(word, X0)
library(rstudioapi)
library(tidyverse)
library(dplyr)
library(rvest)
library(rlist)
library(tidytext)
source('transcriptTED.R')
setwd(dirname(getSourceEditorContext()$path))
# Disable text encoding as 'factors'
options(stringsAsFactors = FALSE)
# URL of the playlist
# "https://www.ted.com/playlists/78/climate_change_oh_it_s_real"
# "https://www.ted.com/playlists/126/the_big_picture"
playlisturl <- "https://www.ted.com/playlists/78/climate_change_oh_it_s_real"
htmlpage <- playlisturl %>% read_html()
htmlpage %>% write_html("playlist.html")
# scrape list of videos from playlist
videolist <- htmlpage %>% html_nodes('body') %>%
html_nodes('a') %>%
html_attr('href') %>%
as.vector() %>%
gsub(pattern = '\\?(.*)', replacement = "")
# clean list of video
videolist <- videolist[grep(x = videolist, pattern = '/talks/')]
videolist <- videolist[-1]
videolist <- paste('https://www.ted.com/', videolist, '/transcript', sep = "")
trnslist <- vector()
for (val in videolist) {
temp <- val %>% transcriptTED()
trnslist <- trnslist %>% list.append(temp)
}
strn <- "TED.com translations are made possible by volunteer translators. Learn more about the Open Translation Project."
trnslist <- trnslist[-grep(pattern = strn, x = trnslist)]
strn <- "© TED Conferences, LLC. All rights reserved."
trnslist <- trnslist %>% gsub(pattern = strn,replacement = "©")
trnslist <- split(trnslist, cumsum(trnslist == "©"))
trnslist <- trnslist[-length(trnslist)]
trnslist %>% saveRDS(file = "texttranscription.rds")
trnslist %>% glimpse()
trnslist[1] %>% cbind(speech = "X0")
trnslist[1] %>% as.data.frame() %>% cbind(speech = "X0")
print(val)
for (val in 1:length(trnslist)) {
print(val)
}
df <- data.frame()
trnslist[val] %>% as.data.frame() %>% cbind(speech = as.character(val))
df <- rbind(df, trnslist[val] %>% as.data.frame() %>% cbind(speech = as.character(val)))
for (val in 1:length(trnslist)) {
df <- rbind(df, trnslist[val] %>% as.data.frame() %>% cbind(speech = as.character(val)))
print(val)
}
df <- rbind(df, trnslist[val] %>% as.data.frame() %>% colnames("line") %>% cbind(speech = as.character(val)))
View(df)
df <- rbind(df, trnslist[val] %>% as.data.frame(col.names = "text") %>% cbind(speech = as.character(val)))
for (val in 1:length(trnslist)) {
df <- rbind(df, trnslist[val] %>% as.data.frame(col.names = "text") %>% cbind(speech = as.character(val)))
print(val)
}
df <- rbind(df, trnslist[val] %>% as.data.frame(col.names = c("line","text")) %>% cbind(speech = as.character(val)))
for (val in 1:length(trnslist)) {
df <- rbind(df, trnslist[val] %>% as.data.frame(col.names = c("line","text")) %>% cbind(speech = as.character(val)))
print(val)
}
df <- rbind(df, trnslist[val] %>% as.data.frame(col.names = c("text")) %>% cbind(speech = as.character(val)))
df <- data.frame()
for (val in 1:length(trnslist)) {
df <- rbind(df, trnslist[val] %>% as.data.frame(col.names = "text") %>% cbind(speech = as.character(val)))
print(val)
}
View(df)
dfspeech %>%
unnest_tokens(word, text)
dfspeech <- data.frame()
for (val in 1:length(trnslist)) {
dfspeech <- rbind(df, trnslist[val] %>% as.data.frame(col.names = "text") %>% cbind(speech = as.character(val)))
print(val)
}
dfspeech %>%
unnest_tokens(word, text)
dfspeech <- dfspeech %>%
unnest_tokens(word, text)
dfspeech %>% glimpse()
View(dfspeech)
dfspeech <- dfspeech %>%
unnest_tokens(word, text) %>%
count(speech, word, sort = T)
dfspeech <- data.frame()
for (val in 1:length(trnslist)) {
dfspeech <- rbind(df, trnslist[val] %>% as.data.frame(col.names = "text") %>% cbind(speech = as.character(val)))
print(val)
}
dfspeech <- dfspeech %>%
unnest_tokens(word, text) %>%
count(speech, word, sort = T)
dfspeech
dfspeech <- data.frame()
for (val in 1:length(trnslist)) {
dfspeech <- rbind(df, trnslist[val] %>% as.data.frame(col.names = "text") %>% cbind(speech = as.character(val)))
print(val)
}
dfwords <- dfspeech %>%
unnest_tokens(word, text) %>%
count(speech, word, sort = T)
total_words <- dfwords %>%
group_by(speech) %>%
summarize(total = sum(n))
total_words
dfwords <- left_join(dfwords, total_words)
dfwords
dfspeech <- data.frame()
for (val in 1:length(trnslist)) {
dfspeech <- rbind(df, trnslist[val] %>% as.data.frame(col.names = "text") %>% cbind(speech = as.character(val)))
print(val)
}
dfwords <- dfspeech %>%
unnest_tokens(word, text) %>%
count(speech, word, sort = T)
total_words <- dfwords %>%
group_by(speech) %>%
summarize(total = sum(n))
dfwords <- left_join(dfwords, total_words)
dfwords
dfwords <- dfwords %>%
bind_tf_idf(word, speech, n)
dfwords
dfwords %>%
arrange(desc(tf_idf))
dfwords %>%
arrange(desc(tf_idf)) %>%
head(50)
dfwords %>%
arrange(desc(tf_idf)) %>%
head(50) %>% print()
dfwords %>%
arrange(desc(tf_idf)) %>%
head(50) %>% print()
source('C:/Users/fcalv/Desktop/R folder/Climatedream/TED/script.R', echo=TRUE)
source('C:/Users/fcalv/Desktop/R folder/Climatedream/TED/script.R', echo=TRUE)
source('C:/Users/fcalv/Desktop/R folder/Climatedream/TED/script.R', echo=TRUE)
for (val in 1:length(trnslist)) {
# dfspeech <- rbind(df, trnslist[val] %>% as.data.frame(col.names = "text") %>% cbind(speech = as.character(val)))
print(val)
}
source('C:/Users/fcalv/Desktop/R folder/Climatedream/TED/script.R', echo=TRUE)
dfspeech
View(dfspeech)
dfbigrams <- dfspeech %>%
unnest_tokens(bigram, text, token = 'ngrams', n =2)
dfbigrams
dfbigrams %>%
count(bigram, sort = T)
dfbisep <- dfbigrams %>%
separate(bigram, c("word1", "word2"), sep = " ")
adbifiltered <- dfbisep %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word)
dfbisep
dbifiltered <- dfbisep %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word)
dfbifiltered <- dfbisep %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word)
dfbifiltered
dfbifiltered %>%
count(word1,word2,n,sort = T)
dfbifiltered %>%
count(word1, word2, sort = T)
bigr_tf_idf <- dfbigrams %>%
count(speech, bigram) %>%
bind_tf_idf(bigram, speech, n) %>%
arrange(desc(tf_idf))
bigr_tf_idf
bigr_tf_idf <- dfbigrams %>%
count(bigram) %>%
bind_tf_idf(bigram, speech, n) %>%
arrange(desc(tf_idf))
bigr_tf_idf <- dfbigrams %>%
count(bigram) %>%
bind_tf_idf(bigram, n) %>%
arrange(desc(tf_idf))
bigr_tf_idf <- dfbigrams %>%
count(speech, bigram) %>%
bind_tf_idf(bigram, speech, n) %>%
arrange(desc(tf_idf))
bigr_tf_idf
bigr_tf_idf <- dfbigrams %>%
count(bigram)
bigr_tf_idf <- dfbigrams %>%
count(speech, bigram) %>%
bind_tf_idf(bigram, speech, n) %>%
arrange(desc(tf_idf))
source('C:/Users/fcalv/Desktop/R folder/Climatedream/TED/script.R', echo=TRUE)
bigr_tf_idf
source('C:/Users/fcalv/Desktop/R folder/Climatedream/TED/script.R', echo=TRUE)
bigr_tf_idf
library(rstudioapi)
library(tidyverse)
library(dplyr)
library(rvest)
library(rlist)
library(tidytext)
source('transcriptTED.R')
setwd(dirname(getSourceEditorContext()$path))
# Disable text encoding as 'factors'
options(stringsAsFactors = FALSE)
# URL of the playlist
# "https://www.ted.com/playlists/78/climate_change_oh_it_s_real"
# "https://www.ted.com/playlists/126/the_big_picture"
# "https://www.ted.com/playlists/154/how_do_you_solve_a_problem_lik"
playlisturl <- c("https://www.ted.com/playlists/126/the_big_picture",
"https://www.ted.com/playlists/78/climate_change_oh_it_s_real",
"https://www.ted.com/playlists/154/how_do_you_solve_a_problem_lik")
for (val in playlisturl) {
htmlpage <- playlisturl %>% read_html()
htmlpage %>% write_html(paste("playlist", as.character(val),".html",sep = "")
# scrape list of videos from playlist
videolist <- htmlpage %>% html_nodes('body') %>%
html_nodes('a') %>%
html_attr('href') %>%
as.vector() %>%
gsub(pattern = '\\?(.*)', replacement = "")
# clean list of video
videolist <- videolist[grep(x = videolist, pattern = '/talks/')]
videolist <- videolist[-1]
videolist <- paste('https://www.ted.com/', videolist, '/transcript', sep = "")
fulllist <- rbind(fulllist,videolist)
}
for (val in playlisturl) {
htmlpage <- playlisturl[val] %>% read_html()
htmlpage %>% write_html(paste("playlist", as.character(val),".html",sep = "")
# scrape list of videos from playlist
videolist <- htmlpage %>% html_nodes('body') %>%
html_nodes('a') %>%
html_attr('href') %>%
as.vector() %>%
gsub(pattern = '\\?(.*)', replacement = "")
# clean list of video
videolist <- videolist[grep(x = videolist, pattern = '/talks/')]
videolist <- videolist[-1]
videolist <- paste('https://www.ted.com/', videolist, '/transcript', sep = "")
fulllist <- rbind(fulllist,videolist)
}
for (val in playlisturl) {
playlisturl <- c("https://www.ted.com/playlists/126/the_big_picture",
"https://www.ted.com/playlists/78/climate_change_oh_it_s_real",
"https://www.ted.com/playlists/154/how_do_you_solve_a_problem_lik")
for (val in playlisturl) {
htmlpage <- playlisturl[val] %>% read_html()
htmlpage %>% write_html(paste("playlist", as.character(val),".html",sep = "")
# scrape list of videos from playlist
videolist <- htmlpage %>% html_nodes('body') %>%
html_nodes('a') %>%
html_attr('href') %>%
as.vector() %>%
gsub(pattern = '\\?(.*)', replacement = "")
# clean list of video
videolist <- videolist[grep(x = videolist, pattern = '/talks/')]
videolist <- videolist[-1]
videolist <- paste('https://www.ted.com/', videolist, '/transcript', sep = "")
fulllist <- rbind(fulllist,videolist)
}
trnslist <- vector()
for (val in videolist) {
temp <- val %>% transcriptTED()
trnslist <- trnslist %>% list.append(temp)
}
strn <- "TED.com translations are made possible by volunteer translators. Learn more about the Open Translation Project."
trnslist <- trnslist[-grep(pattern = strn, x = trnslist)]
strn <- "© TED Conferences, LLC. All rights reserved."
trnslist <- trnslist %>% gsub(pattern = strn,replacement = "©")
trnslist <- split(trnslist, cumsum(trnslist == "©"))
trnslist <- trnslist[-length(trnslist)]
# trnslist %>% saveRDS(file = "texttranscription.rds")
trnslist %>% glimpse
dfspeech <- data.frame()
for (val in 1:length(trnslist)) {
dfspeech <- rbind(dfspeech, trnslist[val] %>% as.data.frame(col.names = "text") %>% cbind(speech = as.character(val)))
print(val)
}
dfwords <- dfspeech %>%
unnest_tokens(word, text) %>%
count(speech, word, sort = T)
total_words <- dfwords %>%
group_by(speech) %>%
summarize(total = sum(n))
dfwords <- left_join(dfwords, total_words)
dfwords <- dfwords %>%
bind_tf_idf(word, speech, n)
dfwords %>%
arrange(desc(tf_idf))
# same with bigrams
dfbigrams <- dfspeech %>%
unnest_tokens(bigram, text, token = 'ngrams', n =2)
# count
# dfbigrams %>%
# count(bigram, sort = T)
# filter stopwords
dfbisep <- dfbigrams %>%
separate(bigram, c("word1", "word2"), sep = " ")
dfbifiltered <- dfbisep %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word)
#dfbifiltered %>%
#  count(word1, word2, sort = T)
# tf_idf
bigr_tf_idf <- dfbigrams %>%
count(speech, bigram) %>%
bind_tf_idf(bigram, speech, n) %>%
arrange(desc(tf_idf))
bigr_tf_idf
for (val in playlisturl)
{
htmlpage <- playlisturl[val] %>% read_html()
htmlpage %>% write_html(paste("playlist", as.character(val),".html",sep = "")
# scrape list of videos from playlist
videolist <- htmlpage %>% html_nodes('body') %>%
html_nodes('a') %>%
html_attr('href') %>%
as.vector() %>%
gsub(pattern = '\\?(.*)', replacement = "")
# clean list of video
videolist <- videolist[grep(x = videolist, pattern = '/talks/')]
videolist <- videolist[-1]
videolist <- paste('https://www.ted.com/', videolist, '/transcript', sep = "")
fulllist <- rbind(fulllist,videolist)
}
for (val in playlisturl) {
htmlpage <- playlisturl[val] %>% read_html()
htmlpage %>% write_html(paste("playlist", as.character(val),".html",sep = ""))
# scrape list of videos from playlist
videolist <- htmlpage %>% html_nodes('body') %>%
html_nodes('a') %>%
html_attr('href') %>%
as.vector() %>%
gsub(pattern = '\\?(.*)', replacement = "")
# clean list of video
videolist <- videolist[grep(x = videolist, pattern = '/talks/')]
videolist <- videolist[-1]
videolist <- paste('https://www.ted.com/', videolist, '/transcript', sep = "")
fulllist <- rbind(fulllist,videolist)
}
fulllist <- vector()
for (val in playlisturl) {
htmlpage <- playlisturl[val] %>% read_html()
htmlpage %>% write_html(paste("playlist", as.character(val),".html",sep = ""))
# scrape list of videos from playlist
videolist <- htmlpage %>% html_nodes('body') %>%
html_nodes('a') %>%
html_attr('href') %>%
as.vector() %>%
gsub(pattern = '\\?(.*)', replacement = "")
# clean list of video
videolist <- videolist[grep(x = videolist, pattern = '/talks/')]
videolist <- videolist[-1]
videolist <- paste('https://www.ted.com/', videolist, '/transcript', sep = "")
fulllist <- rbind(fulllist,videolist)
}
fulllist <- rbind(fulllist,videolist)
htmlpage <- playlisturl[1] %>% read_html()
htmlpage %>% write_html(paste("playlist", as.character(val),".html",sep = ""))
for (val in 1:length(playlisturl)) {
htmlpage <- playlisturl[val] %>% read_html()
htmlpage %>% write_html(paste("playlist", as.character(val),".html",sep = ""))
# scrape list of videos from playlist
videolist <- htmlpage %>% html_nodes('body') %>%
html_nodes('a') %>%
html_attr('href') %>%
as.vector() %>%
gsub(pattern = '\\?(.*)', replacement = "")
# clean list of video
videolist <- videolist[grep(x = videolist, pattern = '/talks/')]
videolist <- videolist[-1]
videolist <- paste('https://www.ted.com/', videolist, '/transcript', sep = "")
fulllist <- rbind(fulllist,videolist)
}
View(fulllist)
fulllist <- vector()
for (val in 1:length(playlisturl)) {
htmlpage <- playlisturl[val] %>% read_html()
htmlpage %>% write_html(paste("playlist", as.character(val),".html",sep = ""))
# scrape list of videos from playlist
videolist <- htmlpage %>% html_nodes('body') %>%
html_nodes('a') %>%
html_attr('href') %>%
as.vector() %>%
gsub(pattern = '\\?(.*)', replacement = "")
# clean list of video
videolist <- videolist[grep(x = videolist, pattern = '/talks/')]
videolist <- videolist[-1]
videolist <- paste('https://www.ted.com/', videolist, '/transcript', sep = "")
fulllist <- cbind(fulllist,videolist)
}
fulllist <- vector()
for (val in 1:length(playlisturl)) {
htmlpage <- playlisturl[val] %>% read_html()
htmlpage %>% write_html(paste("playlist", as.character(val),".html",sep = ""))
# scrape list of videos from playlist
videolist <- htmlpage %>% html_nodes('body') %>%
html_nodes('a') %>%
html_attr('href') %>%
as.vector() %>%
gsub(pattern = '\\?(.*)', replacement = "")
# clean list of video
videolist <- videolist[grep(x = videolist, pattern = '/talks/')]
videolist <- videolist[-1]
videolist <- paste('https://www.ted.com/', videolist, '/transcript', sep = "")
fulllist <- append(fulllist,videolist)
}
source('C:/Users/fcalv/Desktop/R folder/Climatedream/TED/script.R', echo=TRUE)
dfbifiltered
source('C:/Users/fcalv/Desktop/R folder/Climatedream/TED/script.R', echo=TRUE)
dfbifiltered
dfbifiltered %>%
count(word1, word2, sort = T)
fulllist
unique(fulllist)
source('C:/Users/fcalv/Desktop/R folder/Climatedream/TED/script.R', echo=TRUE)
source('C:/Users/fcalv/Desktop/R folder/Climatedream/TED/script.R', echo=TRUE)
